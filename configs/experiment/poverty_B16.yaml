# @package _global_

# to execute this experiment run:
# python train.py experiment=example

# change data transform and loss combination (2)

defaults:
  - override /data: poverty_contrastive.yaml
  #- override /model: prompt_tta_ViT_L14_CLIP_default.yaml
  # - override /model: prompt_tta_ViT_L14_px336_CLIP_default.yaml
  - override /model: prompt_tta_ViT_B16_CLIP.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

trainer:
#  devices: [2]
  max_epochs: 100
  max_steps: 200000000
  # num_sanity_val_steps: 10
  # gradient_clip_val: 1
  # deterministic: True
  # precision: 16
    
# path to data directory
paths:
  data_dir: "/data/tao/wilds/data"

callbacks:
  model_checkpoint:
    monitor: r_all

model:
  train_support_ratio: 0.2
  text_loss_coeff: 0.1
  
  optimizer:
    optimizer: adamw
    base_lr: 0.0006
    weight_decay: 0.01
    momentum: 0.9
  loss_func:                                                                                                                                                  
    _target_: torch.nn.L1Loss

  scheduler:
    # scheduler: hard_steps
    warmup_epoch: 0
    total_epoch: 100
  model:
    side_layers: 1
    #decoder_attention_downsample_rate: 1
    #decoder_mlp_dim: 2048
    learnable_scaling: True
    pool_length: 5                                                                                                      
    pool_size: 5

data:   
    batch_size: 64
    input_resolution: 224
    # num_workers: 0

task_name: "Poverty_S6GClip0_0.0001_64_0.2_30E_CLIPS_TLoss0.1_Cache5_5_16_23"
# task_name: "camelyon_check"
test: False
seed: 42
